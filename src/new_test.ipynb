{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1.0e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, D, M, C):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(D, M * 2),\n",
    "            nn.BatchNorm1d(M * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(M * 2, M),\n",
    "            nn.BatchNorm1d(M),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(M, M // 2),\n",
    "            nn.BatchNorm1d(M // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(M // 2, C),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encode(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, D, M, C):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(C, M // 2),\n",
    "            nn.BatchNorm1d(M // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(M // 2, M),\n",
    "            nn.BatchNorm1d(M),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(M, M * 2),\n",
    "            nn.BatchNorm1d(M * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(M * 2, D),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decode(x)\n",
    "\n",
    "\n",
    "class Quantizer(nn.Module):\n",
    "    def __init__(self, input_dim, codebook_dim, temp=1.0e7):\n",
    "        super(Quantizer, self).__init__()\n",
    "        self.temp = temp\n",
    "        self.input_dim = input_dim\n",
    "        self.codebook_dim = codebook_dim\n",
    "        self.codebook = nn.Parameter(\n",
    "            torch.FloatTensor(\n",
    "                1,\n",
    "                self.codebook_dim,\n",
    "            ).uniform_(-1 / self.codebook_dim, 1 / self.codebook_dim)\n",
    "        )\n",
    "\n",
    "    def indices2codebook(self, indices_onehot):\n",
    "        return torch.matmul(indices_onehot, self.codebook.t()).squeeze()\n",
    "\n",
    "    def indices_to_onehot(self, inputs_shape, indices):\n",
    "        indices_hard = torch.zeros(inputs_shape[0], inputs_shape[1], self.codebook_dim)\n",
    "        indices_hard.scatter_(2, indices, 1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs_shape = inputs.shape\n",
    "        inputs_repeat = inputs.unsqueeze(2).repeat(1, 1, self.codebook_dim)\n",
    "        distances = torch.exp(\n",
    "            -torch.sqrt(torch.pow(inputs_repeat - self.codebook.unsqueeze(1), 2))\n",
    "        )\n",
    "        indices = torch.argmax(distances, dim=2).unsqueeze(2)\n",
    "        indices_hard = self.indices_to_onehot(\n",
    "            inputs_shape=inputs_shape, indices=indices\n",
    "        )\n",
    "        indices_soft = torch.softmax(self.temp * distances, -1)\n",
    "        quantized = self.indices2codebook(indices_onehot=indices_soft)\n",
    "        return (indices_soft, indices_hard, quantized)\n",
    "\n",
    "\n",
    "class Uniform_Entropy_Coding(nn.Module):\n",
    "    def __init__(self, code_dim, codebook_dim):\n",
    "        super(Uniform_Entropy_Coding, self).__init__()\n",
    "        self.code_dim = code_dim\n",
    "        self.codebook_dim = codebook_dim\n",
    "        self.probs = torch.softmax(torch.ones(1, self.code_dim, self.codebook_dim), -1)\n",
    "\n",
    "    def sample(self, quantizer=None, B=10):\n",
    "        code = torch.zeros(B, self.code_dim, self.codebook_dim)\n",
    "        for b in range(B):\n",
    "            indx = torch.multinomial(\n",
    "                torch.softmax(self.probs, -1).squeeze(0), 1\n",
    "            ).squeeze()\n",
    "            for i in range(self.code_dim):\n",
    "                code[b, i, indx[i]] = 1\n",
    "\n",
    "        code = quantizer.indices2codebook(code)\n",
    "        return code\n",
    "\n",
    "    def forward(self, z, x=None):\n",
    "        p = torch.clamp(self.probs, EPS, 1.0 - EPS)\n",
    "        return -torch.sum(z * torch.log(p), 2)\n",
    "\n",
    "\n",
    "class Independent_Entropy_Coding(nn.Module):\n",
    "    def __init__(self, code_dim, codebook_dim):\n",
    "        super(Independent_Entropy_Coding, self).__init__()\n",
    "        self.code_dim = code_dim\n",
    "        self.codebook_dim = codebook_dim\n",
    "\n",
    "        self.probs = nn.Parameter(torch.ones(1, self.code_dim, self.codebook_dim))\n",
    "\n",
    "    def sample(self, quantizer=None, B=10):\n",
    "        code = torch.zeros(B, self.code_dim, self.codebook_dim)\n",
    "        for b in range(B):\n",
    "            indx = torch.multinomial(\n",
    "                torch.softmax(self.probs, -1).squeeze(0), 1\n",
    "            ).squeeze()\n",
    "            for i in range(self.code_dim):\n",
    "                code[b, i, indx[i]] = 1\n",
    "\n",
    "        code = quantizer.indices2codebook(code)\n",
    "        return code\n",
    "\n",
    "    def forward(self, z, x=None):\n",
    "        p = torch.clamp(torch.softmax(self.probs, -1), EPS, 1.0 - EPS)\n",
    "        return -torch.sum(z * torch.log(p), 2)\n",
    "\n",
    "\n",
    "class Casual_Conv1d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        dilation,\n",
    "        stride=1,\n",
    "        A=False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(Casual_Conv1d, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation = dilation\n",
    "        self.A = A\n",
    "        self.padding = (kernel_size - 1) * dilation + A * 1\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.pad(x, (self.padding, 0))\n",
    "        x = self.conv1d(x)\n",
    "        if self.A:\n",
    "            return x[:, :, :-1]\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class ARM_Entropy_Coding(nn.Module):\n",
    "    def __init__(self, code_dim, codebook_dim, E=8, M_kernels=32, kernel=4):\n",
    "        super(ARM_Entropy_Coding, self).__init__()\n",
    "        self.code_dim = code_dim\n",
    "        self.codebook_dim = codebook_dim\n",
    "        self.arm_net = nn.Sequential(\n",
    "            Casual_Conv1d(\n",
    "                in_channels=1,\n",
    "                out_channels=M_kernels,\n",
    "                dilation=1,\n",
    "                kernel_size=kernel,\n",
    "                A=True,\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.LeakyReLU(),\n",
    "            Casual_Conv1d(\n",
    "                in_channels=M_kernels,\n",
    "                out_channels=M_kernels,\n",
    "                dilation=1,\n",
    "                kernel_size=kernel,\n",
    "                A=False,\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.LeakyReLU(),\n",
    "            Casual_Conv1d(\n",
    "                in_channels=M_kernels,\n",
    "                out_channels=E,\n",
    "                dilation=1,\n",
    "                kernel_size=kernel,\n",
    "                A=False,\n",
    "                bias=True,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def f(self, x):\n",
    "        h = self.arm_net(x.unsqueeze(1))\n",
    "        # print(\"h_size\", h.size())\n",
    "        h = h.permute(0, 2, 1)\n",
    "        # print(\"h_size\", h.size())\n",
    "        p = torch.softmax(h, 2)\n",
    "        # print(\"p_size\", p.size())\n",
    "\n",
    "        return p\n",
    "\n",
    "    def sample(self, quantizer=None, B=10):\n",
    "        x_new = torch.zeros((B, self.code_dim))\n",
    "\n",
    "        for d in range(self.code_dim):\n",
    "            p = self.f(x_new)\n",
    "            indx_d = torch.multinomial(p[:, d, :], num_samples=1)\n",
    "            codebook_value = quantizer.codebook[0, indx_d].squeeze()\n",
    "            x_new[:, d] = codebook_value\n",
    "\n",
    "        return x_new\n",
    "\n",
    "    def forward(self, z, x):\n",
    "        p = self.f(x)\n",
    "        return -torch.sum(z * torch.log(p), 2)\n",
    "\n",
    "\n",
    "class Neural_Compressor(nn.Module):\n",
    "    def __init__(\n",
    "        self, encoder, decoder, entropy_coding, quantizer, beta=1, detaching=False\n",
    "    ):\n",
    "        super(Neural_Compressor, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.entropy_coding = entropy_coding\n",
    "        self.quantizer = quantizer\n",
    "        self.beta = beta\n",
    "        self.detaching = detaching\n",
    "\n",
    "    def forward(self, x, reduction=\"avg\"):\n",
    "        z = self.encoder(x)\n",
    "        quantizer_out = self.quantizer(z)\n",
    "        x_rec = self.decoder(quantizer_out[2])\n",
    "\n",
    "        Distortion = torch.mean(torch.pow(x - x_rec, 2), (1))\n",
    "\n",
    "        Rate = torch.mean(self.entropy_coding(quantizer_out[0], quantizer_out[2]), 1)\n",
    "        objective = Distortion + self.beta * Rate\n",
    "\n",
    "        if reduction == \"sum\":\n",
    "            return objective.sum(), Distortion.sum(), Rate.sum()\n",
    "        else:\n",
    "            return objective.mean(), Distortion.mean(), Rate.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 64\n",
    "C = 16\n",
    "E = 8\n",
    "M = 256\n",
    "M_kernels = 32\n",
    "kernel = 4\n",
    "entropy_coding_type = 'arm'\n",
    "lr = 1e-3\n",
    "num_epochs = 1000\n",
    "max_patience = 50\n",
    "beta = 1\n",
    "\n",
    "\n",
    "encoder = Encoder(D=D, M=M, C=C)\n",
    "\n",
    "decoder = Decoder(D=D, M=M, C=C)\n",
    "\n",
    "quantizer = Quantizer(input_dim=C, codebook_dim=E)\n",
    "\n",
    "kernel = 4\n",
    "entropy_coding = ARM_Entropy_Coding(\n",
    "    code_dim=C,\n",
    "    codebook_dim=E,\n",
    "    E=E,\n",
    "    M_kernels=M_kernels,\n",
    "    kernel=kernel,\n",
    ")\n",
    "\n",
    "\n",
    "model = Neural_Compressor(encoder=encoder, decoder=decoder, entropy_coding=entropy_coding, quantizer=quantizer, beta=beta )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model type .model by pytorch\n",
    "model = torch.load('/workspace/nttrang2108/VHT/Image_Neural_Compression/weights/img_8/img_8_cus/best_model_440_D_64_C_16_E_8_M_256_loss_13.1994.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neural_Compressor(\n",
       "  (encoder): Encoder(\n",
       "    (encode): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=512, bias=True)\n",
       "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (7): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU()\n",
       "      (9): Linear(in_features=128, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (decode): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=128, bias=True)\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (7): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (8): ReLU()\n",
       "      (9): Linear(in_features=512, out_features=64, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (entropy_coding): ARM_Entropy_Coding(\n",
       "    (arm_net): Sequential(\n",
       "      (0): Casual_Conv1d(\n",
       "        (conv1d): Conv1d(1, 32, kernel_size=(4,), stride=(1,))\n",
       "      )\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Casual_Conv1d(\n",
       "        (conv1d): Conv1d(32, 32, kernel_size=(4,), stride=(1,))\n",
       "      )\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Casual_Conv1d(\n",
       "        (conv1d): Conv1d(32, 8, kernel_size=(4,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (quantizer): Quantizer()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    def __init__(self, mode ='train', transforms = None):\n",
    "        digits = load_digits()\n",
    "        if mode =='train':\n",
    "            self.data =digits.data[:1000].astype(np.float32)\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "        \n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = Digits(mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "IMG_IDs = [110, 120, 130, 140]\n",
    "z_sampled = model.entropy_coding.sample(quantizer=model.quantizer, B = 9)\n",
    "x_sampled = model.decoder(z_sampled)\n",
    "\n",
    "x_real = torch.from_numpy(test_data.__getitem__(IMG_IDs))\n",
    "print(x_real.shape)\n",
    "x_encoder = model.encoder(x_real)\n",
    "# print(x_encoder)\n",
    "# print(\"-----\", model.quantizer(model.encoder(x_real)))\n",
    "x_rec = model.decoder(model.quantizer(model.encoder(x_real))[-1])\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(6, 8))\n",
    "i = 0\n",
    "for i in range(len(IMG_IDs)):\n",
    "    axs[i,0].imshow(x_real[i].reshape(8,8).detach().numpy())\n",
    "    axs[i,0].set_title('original')\n",
    "    axs[i,0].axis('off')\n",
    "    \n",
    "    axs[i,1].imshow(x_rec[i].reshape(8,8).detach().numpy())\n",
    "    axs[i,1].set_title('reconstruction')\n",
    "    axs[i,1].axis('off')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
